#!/usr/bin/env python3
"""
Final comprehensive parser validation using SDL API
Validates field extraction for all 100 parsers using the correct parser= query
"""
import os
import sys
import json
import time
import requests
import argparse
from datetime import datetime, timezone, timedelta
from collections import defaultdict

# Configuration
SDL_API_TOKEN = os.getenv("S1_SDL_API_TOKEN", "")
SDL_API_URL = os.getenv("S1_SDL_API_URL", "https://xdr.us1.sentinelone.net/api/query")

sys.path.insert(0, 'event_generators/shared')
from hec_sender import PROD_MAP, SOURCETYPE_MAP, MARKETPLACE_PARSER_MAP

def query_parser_events(parser_name: str, hours_back: int = 4) -> list:
    """Query SDL for events processed by a specific parser"""
    if not SDL_API_TOKEN:
        return []
    headers = {
        'Authorization': f'Bearer {SDL_API_TOKEN}',
        'Content-Type': 'application/json'
    }
    
    end_time = datetime.now(timezone.utc)
    start_time = end_time - timedelta(hours=hours_back)
    
    query_payload = {
        'queryType': 'log',
        'filter': f'* contains "{parser_name}"',
        'startTime': start_time.isoformat(),
        'endTime': end_time.isoformat()
    }
    
    try:
        response = requests.post(SDL_API_URL, headers=headers, json=query_payload, timeout=15)
        if response.status_code == 200:
            result = response.json()
            # Extract events from matches array
            matches = result.get('matches', [])
            events = []
            for match in matches:
                # Combine attributes and other fields into event object
                event = match.get('attributes', {}).copy()
                event.update({
                    'severity': match.get('severity'),
                    'timestamp': match.get('timestamp'),
                    'message': match.get('message', ''),
                    'thread': match.get('thread', ''),
                    'session': match.get('session', '')
                })
                events.append(event)
            return events
        return []
    except Exception:
        return []

def analyze_field_extraction(events: list) -> dict:
    """Analyze field extraction quality from parsed events"""
    if not events:
        return {"status": "no_events", "field_count": 0, "ocsf_score": 0}
    
    all_fields = set()
    ocsf_fields = set()
    has_observables = False
    
    for event in events:
        event_fields = set(event.keys())
        all_fields.update(event_fields)
        
        # Check for OCSF compliance
        for field in event_fields:
            if any(field.startswith(prefix) for prefix in [
                'activity_', 'category_', 'class_', 'severity_', 'status_', 
                'time', 'metadata', 'actor', 'device', 'src_endpoint', 'dst_endpoint'
            ]):
                ocsf_fields.add(field)
        
        # Check for observables
        if 'observables' in event or any('observable' in str(v) for v in event.values()):
            has_observables = True
    
    # Calculate OCSF compliance score
    ocsf_score = 0
    if len(ocsf_fields) >= 10:
        ocsf_score = 100
    elif len(ocsf_fields) >= 5:
        ocsf_score = 80
    elif len(ocsf_fields) >= 3:
        ocsf_score = 60
    elif len(ocsf_fields) >= 1:
        ocsf_score = 40
    
    # Bonus for observables
    if has_observables:
        ocsf_score = min(100, ocsf_score + 10)
    
    return {
        "status": "success",
        "event_count": len(events),
        "field_count": len(all_fields),
        "ocsf_fields": len(ocsf_fields),
        "ocsf_score": ocsf_score,
        "has_observables": has_observables,
        "sample_fields": sorted(list(all_fields))[:20],
        "ocsf_sample": sorted(list(ocsf_fields))[:10]
    }

def validate_marketplace_parsers():
    """Validate marketplace parsers with enhanced OCSF compliance"""
    print("\n" + "=" * 70)
    print("MARKETPLACE PARSER VALIDATION - ENHANCED OCSF ANALYSIS")
    print("=" * 70)
    print(f"Checking {len(MARKETPLACE_PARSER_MAP)} marketplace parsers")
    print()
    
    results = {}
    categories = {
        "excellent": [],    # OCSF score >= 80 and observables
        "good": [],        # OCSF score >= 60
        "basic": [],       # OCSF score >= 20  
        "poor": [],        # OCSF score < 20
        "no_events": []    # No events found
    }
    
    total_events_found = 0
    
    print("Querying marketplace parsers for enhanced field extraction...")
    print("-" * 70)
    
    for i, (marketplace_parser, generator_name) in enumerate(MARKETPLACE_PARSER_MAP.items(), 1):
        print(f"[{i:3d}/{len(MARKETPLACE_PARSER_MAP)}] {marketplace_parser:45s} ‚Üí {generator_name:25s}", end=" ", flush=True)
        
        # Query events for this marketplace parser
        events = query_parser_events(marketplace_parser)
        
        # Analyze field extraction
        analysis = analyze_field_extraction(events)
        results[marketplace_parser] = {
            "generator": generator_name,
            "analysis": analysis
        }
        
        # Categorize result
        score = analysis.get("ocsf_score", 0)
        event_count = analysis.get("event_count", 0)
        has_observables = analysis.get("has_observables", False)
        
        if analysis["status"] == "no_events":
            categories["no_events"].append(marketplace_parser)
            print("‚ùå NO EVENTS")
        elif score >= 80 and has_observables:
            categories["excellent"].append(marketplace_parser)
            print(f"üåü EXCELLENT ({score}% OCSF, {event_count} events, observables)")
            total_events_found += event_count
        elif score >= 60:
            categories["good"].append(marketplace_parser)  
            print(f"‚úÖ GOOD ({score}% OCSF, {event_count} events)")
            total_events_found += event_count
        elif score >= 20:
            categories["basic"].append(marketplace_parser)
            print(f"‚ö†Ô∏è  BASIC ({score}% OCSF, {event_count} events)")
            total_events_found += event_count
        else:
            categories["poor"].append(marketplace_parser)
            print(f"‚ùå POOR ({score}% OCSF, {event_count} events)")
            total_events_found += event_count
    
    # Print summary
    print("\n" + "=" * 70)
    print("MARKETPLACE PARSER VALIDATION SUMMARY")
    print("=" * 70)
    print(f"Total marketplace parsers analyzed: {len(MARKETPLACE_PARSER_MAP)}")
    print(f"Total events found: {total_events_found}")
    print(f"üåü Excellent (‚â•80% OCSF + observables): {len(categories['excellent'])}")
    print(f"‚úÖ Good (‚â•60% OCSF): {len(categories['good'])}")
    print(f"‚ö†Ô∏è  Basic (‚â•20% OCSF): {len(categories['basic'])}")
    print(f"‚ùå Poor (<20% OCSF): {len(categories['poor'])}")
    print(f"‚ùå No events found: {len(categories['no_events'])}")
    
    # Success rate calculation
    working_parsers = len(categories["excellent"]) + len(categories["good"]) + len(categories["basic"])
    success_rate = (working_parsers / len(MARKETPLACE_PARSER_MAP)) * 100 if MARKETPLACE_PARSER_MAP else 0
    print(f"\nüìä **MARKETPLACE PARSER SUCCESS RATE: {working_parsers}/{len(MARKETPLACE_PARSER_MAP)} ({success_rate:.1f}%)**")
    
    return results, categories

def main():
    print("=" * 70)
    print("COMPREHENSIVE PARSER VALIDATION - SDL API ANALYSIS")
    print("=" * 70)
    print(f"Analysis time: {datetime.now().isoformat()}")
    print(f"SDL API: {SDL_API_URL}")
    print(f"Community parsers: {len(SOURCETYPE_MAP)}")
    print(f"Marketplace parsers: {len(MARKETPLACE_PARSER_MAP)}")
    print()
    
    results = {}
    categories = {
        "excellent": [],    # OCSF score >= 80 and observables
        "good": [],        # OCSF score >= 60
        "basic": [],       # OCSF score >= 20  
        "poor": [],        # OCSF score < 20
        "no_events": []    # No events found
    }
    
    total_events_found = 0
    
    print("Querying parsers for field extraction analysis...")
    print("-" * 70)
    
    for i, (generator_name, parser_name) in enumerate(SOURCETYPE_MAP.items(), 1):
        print(f"[{i:3d}/100] {generator_name:35s} ‚Üí {parser_name:25s}", end=" ", flush=True)
        
        # Query events for this parser
        events = query_parser_events(parser_name)
        
        # Analyze field extraction
        analysis = analyze_field_extraction(events)
        results[generator_name] = {
            "parser": parser_name,
            "analysis": analysis
        }
        
        # Categorize result
        if analysis["status"] == "no_events":
            print("‚ùå No events")
            categories["no_events"].append(generator_name)
        else:
            total_events_found += analysis["event_count"]
            score = analysis["ocsf_score"]
            
            if score >= 80 and analysis["has_observables"]:
                print(f"‚úÖ Excellent ({score}%, {analysis['field_count']} fields)")
                categories["excellent"].append(generator_name)
            elif score >= 60:
                print(f"üü° Good ({score}%, {analysis['field_count']} fields)")  
                categories["good"].append(generator_name)
            elif score >= 20:
                print(f"‚ö†Ô∏è  Basic ({score}%, {analysis['field_count']} fields)")
                categories["basic"].append(generator_name)
            else:
                print(f"üî¥ Poor ({score}%, {analysis['field_count']} fields)")
                categories["poor"].append(generator_name)
        
        time.sleep(0.1)  # Rate limiting
    
    # Generate summary report
    print()
    print("=" * 70)
    print("VALIDATION RESULTS SUMMARY")
    print("=" * 70)
    
    total = len(SOURCETYPE_MAP)
    print(f"Total Parsers Tested: {total}")
    print(f"Total Events Found: {total_events_found}")
    print()
    print("Parser Performance Categories:")
    print(f"‚úÖ Excellent (OCSF + Observables): {len(categories['excellent'])}")
    print(f"üü° Good (Strong OCSF): {len(categories['good'])}")
    print(f"‚ö†Ô∏è  Basic (Limited OCSF): {len(categories['basic'])}")
    print(f"üî¥ Poor (Minimal fields): {len(categories['poor'])}")
    print(f"‚ùå No Events: {len(categories['no_events'])}")
    
    working_parsers = len(categories['excellent']) + len(categories['good'])
    success_rate = (working_parsers / total * 100) if total > 0 else 0
    print(f"\nüìä Parser Success Rate: {success_rate:.1f}% ({working_parsers}/{total})")
    
    if categories['excellent']:
        print(f"\nüåü EXCELLENT PARSERS ({len(categories['excellent'])}):")
        for parser in categories['excellent'][:10]:
            analysis = results[parser]['analysis']
            print(f"   ‚Ä¢ {parser}: {analysis['ocsf_fields']} OCSF fields")
        if len(categories['excellent']) > 10:
            print(f"   ... and {len(categories['excellent']) - 10} more")
    
    if categories['no_events']:
        print(f"\n‚ùå PARSERS WITH NO EVENTS ({len(categories['no_events'])}):")
        for parser in categories['no_events'][:10]:
            print(f"   ‚Ä¢ {parser} ‚Üí {results[parser]['parser']}")
        if len(categories['no_events']) > 10:
            print(f"   ... and {len(categories['no_events']) - 10} more")
        print("\nNote: Events may still be processing. Wait 10-15 minutes after sending.")
    
    # Save detailed results
    output = {
        "timestamp": datetime.now().isoformat(),
        "summary": {
            "total_parsers": total,
            "total_events": total_events_found,
            "excellent": len(categories['excellent']),
            "good": len(categories['good']),
            "basic": len(categories['basic']),
            "poor": len(categories['poor']),
            "no_events": len(categories['no_events']),
            "success_rate": success_rate
        },
        "categories": categories,
        "detailed_results": results
    }
    
    with open("final_parser_validation_results.json", "w") as f:
        json.dump(output, f, indent=2)
    
    # Run marketplace parser validation
    marketplace_results, marketplace_categories = validate_marketplace_parsers()
    
    # Combined summary
    print("\n" + "=" * 70)
    print("COMBINED VALIDATION SUMMARY (COMMUNITY + MARKETPLACE)")
    print("=" * 70)
    
    community_working = len(categories['excellent']) + len(categories['good'])
    marketplace_working = len(marketplace_categories['excellent']) + len(marketplace_categories['good'])
    total_working = community_working + marketplace_working
    total_parsers = len(SOURCETYPE_MAP) + len(MARKETPLACE_PARSER_MAP)
    
    print(f"üìä Community Parsers: {community_working}/{len(SOURCETYPE_MAP)} working ({success_rate:.1f}%)")
    print(f"üè™ Marketplace Parsers: {marketplace_working}/{len(MARKETPLACE_PARSER_MAP)} working")
    print(f"üéØ **TOTAL SUCCESS: {total_working}/{total_parsers} parsers working**")
    print(f"üöÄ **MARKETPLACE ADVANTAGE: {len(MARKETPLACE_PARSER_MAP)} additional production-grade parsers**")
    
    # Save combined results
    combined_output = {
        "timestamp": datetime.now().isoformat(),
        "community_parsers": {
            "summary": {
                "total_parsers": total,
                "total_events": total_events_found,
                "excellent": len(categories['excellent']),
                "good": len(categories['good']),
                "basic": len(categories['basic']),
                "poor": len(categories['poor']),
                "no_events": len(categories['no_events']),
                "success_rate": success_rate
            },
            "categories": categories,
            "detailed_results": results
        },
        "marketplace_parsers": {
            "summary": {
                "total_parsers": len(MARKETPLACE_PARSER_MAP),
                "total_events": sum(r['analysis'].get('event_count', 0) for r in marketplace_results.values()),
                "excellent": len(marketplace_categories['excellent']),
                "good": len(marketplace_categories['good']),
                "basic": len(marketplace_categories['basic']),
                "poor": len(marketplace_categories['poor']),
                "no_events": len(marketplace_categories['no_events']),
                "success_rate": (marketplace_working / len(MARKETPLACE_PARSER_MAP) * 100) if MARKETPLACE_PARSER_MAP else 0
            },
            "categories": marketplace_categories,
            "detailed_results": marketplace_results
        },
        "combined_summary": {
            "total_parsers": total_parsers,
            "community_working": community_working,
            "marketplace_working": marketplace_working,
            "total_working": total_working,
            "overall_success_rate": (total_working / total_parsers * 100) if total_parsers > 0 else 0
        }
    }
    
    with open("comprehensive_parser_validation_results.json", "w") as f:
        json.dump(combined_output, f, indent=2)
    
    print(f"\nüìÅ Comprehensive results saved to: comprehensive_parser_validation_results.json")
    print("‚úÖ Comprehensive validation complete!")
    
    return categories, marketplace_categories

if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="Comprehensive Parser Validation with SDL API")
    parser.add_argument("--community-only", action="store_true", 
                        help="Test only community parsers")
    parser.add_argument("--marketplace-only", action="store_true", 
                        help="Test only marketplace parsers")
    parser.add_argument("--parser", type=str, 
                        help="Test specific parser (community or marketplace)")
    parser.add_argument("--hours-back", type=int, default=4,
                        help="Hours back to search for events (default: 4)")
    
    args = parser.parse_args()
    
    if args.community_only:
        print("Running community parser validation only...")
        main()
    elif args.marketplace_only:
        print("Running marketplace parser validation only...")
        validate_marketplace_parsers()
    elif args.parser:
        print(f"Testing specific parser: {args.parser}")
        # Test single parser logic would go here
        if args.parser in SOURCETYPE_MAP:
            events = query_parser_events(SOURCETYPE_MAP[args.parser], args.hours_back)
            analysis = analyze_field_extraction(events)
            print(f"Parser: {args.parser} ‚Üí {SOURCETYPE_MAP[args.parser]}")
            print(f"Analysis: {json.dumps(analysis, indent=2)}")
        elif args.parser in MARKETPLACE_PARSER_MAP:
            events = query_parser_events(args.parser, args.hours_back)  
            analysis = analyze_field_extraction(events)
            print(f"Marketplace Parser: {args.parser} ‚Üí {MARKETPLACE_PARSER_MAP[args.parser]}")
            print(f"Analysis: {json.dumps(analysis, indent=2)}")
        else:
            print(f"Parser '{args.parser}' not found in community or marketplace parsers")
    else:
        print("Running comprehensive validation (community + marketplace)...")
        main()
